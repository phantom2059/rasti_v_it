# Система автоматической оценки устных ответов на экзамене по русскому языку (в рамках кейса "Sigma" хакатона "Расти в IT")

## Общее описание

Этот скрипт реализует полный пайплайн для **автоматической оценки устных ответов** на экзамене по русскому языку для иностранцев. Система использует современные нейросетевые модели для анализа текстовых ответов и изображений, генерирует описания картинок и выставляет объективные оценки на основе критериев экзамена.

### Ключевые компоненты

1. **Анализ (разметка) изображений** — Qwen2.5-VL (vision-language модель)
2. **Обработка текста** — Qwen2.5-VL (задается только текстовый промпт)
3. **Семантическое сходство** — RuBERT (rubert-tiny2) для оценки схожести описаний
4. **Оценивание** — PEFT (Parameter-Efficient Fine-Tuning) LoRa адаптер + Qwen2.5-VL (базовая модель)

---

## Установка зависимостей
### Требуемые библиотеки (требуется последняя версия):

```
torch
torchvision
transformers
accelerate
tokenizers
peft
qwen-vl-utils
scikit-learn
pandas
numpy
Pillow
requests
tqdm
```

---

## Входные данные

### Формат CSV файла:

Файл должен содержать следующие столбцы:

| Столбец | Тип | Описание |
|---------|-----|---------|
| `№ вопроса` | int | Номер вопроса (1-4) |
| `ID экзамена` | str | Уникальный идентификатор экзамена |
| `ID вопроса` | str | Уникальный идентификатор вопроса |
| `Текст вопроса` | str | Текст задания (может содержать HTML) |
| `Картинка из вопроса` | str/NaN | URL изображения (опционально) |
| `Транскрибация ответа` | str | Исходная транскрибация ответа кандидата |

---

## Параметры конфигурации

```python
# Основные пути
OUTPUT_CSV = "predictions.csv"           # Выходной файл с оценками
ADAPTER_PATH = "qwen_sft_exam"           # Путь к LoRA адаптеру

# Модель
MODEL_NAME = "Qwen/Qwen2.5-VL-3B-Instruct"  # Базовая VL модель

# Параметры инференса
MAX_SEQ_LENGTH = 512                   # Максимальная длина последовательности
BATCH_SIZE = 1                           # Размер батча (рекомендуется 1 для экономии памяти)
MAX_NEW_TOKENS = 512                     # Максимум новых токенов при генерации
REQUEST_TIMEOUT = 50                     # Таймаут загрузки изображений (сек)
```

---

## Основные функции

### 1. Загрузка и обработка изображений

**`load_vl_model()`**
- Загружает Qwen2.5-VL-3B в 4-bit квантизации для экономии памяти
- Использует BitsAndBytes для оптимизации
- Возвращает модель и процессор

**`load_image_from_url(url, timeout)`**
- Загружает изображение из URL
- Обрабатывает ошибки сети и неверные форматы
- Конвертирует в RGB формат

**`generate_image_caption(model, processor, words, url)`**
- Генерирует описание изображения на русском языке
- Начинает описание с одного из предложенных слов
- Ограничивает длину до 512 символов

### 2. Обработка ответов кандидатов

**`get_user_img_answer()`**
- Переобрабатывает транскрибацию ответов для заданий "описание картинки"
- Использует LLM для извлечения чистого описания из исходной транскрибации
- Оптимизирует использование памяти GPU

**`filter_text(text)`**
- Удаляет HTML теги
- Удаляет латинские буквы (оставляет только кириллицу)
- Подготавливает текст вопроса к обработке

### 3. Семантический анализ

**`get_sentence_embedding(sentence)`**
- Использует RuBERT-tiny2 для создания эмбеддингов
- Возвращает вектор размерности 312

**`semantic_similarity_russian(text1, text2)`**
- Вычисляет косинусную схожесть между двумя текстами
- Возвращает значение от 0 до 1

**`get_similarity_feature(saved_links, all_texts)`**
- Сравнивает описание картинки от LLM с ответом кандидата
- Добавляет признак схожести в датасет для улучшения оценивания
- Принцип прост - мы генерируем "идеально верный" вариант описания картинки (основываясь на критериях из кейса), семантическое (смысловое) сходство "идеально верного" варианта и ответа кандидата позволяет оценить качество ответа кандидата

### 4. Генерация подсказок и оценивание

**`build_inference_prompt(row)`**
- Создает детальную подсказку для LLM на основе контекста экзамена
- Включает номер вопроса, тип задания, текст вопроса, ответ кандидата
- Добавляет информацию о схожести с изображением (если применимо)
- Указывает диапазон оценок: 0-1 для вопросов 1,3 или 0-2 для вопросов 2,4

**`predict_batch(model, tokenizer, prompts, question_nums)`**
- Запускает инференс на батче подсказок
- Извлекает числовую оценку из ответа модели
- Валидирует оценки согласно максимальным баллам для каждого вопроса

**`extract_score(text, question_num)`**
- Парсит первое число из текста генерации
- Обрезает оценку по максимально допустимому баллу
- Гарантирует валидный диапазон (0 до max_score)

---

## Номера вопросов и возможные баллы

| № вопроса | Возможные баллы |
|-----------|-----------|
| Вопрос 1 | 0 - 1 |
| Вопрос 2 | 0 - 2 |
| Вопрос 3 | 0 - 1 |
| Вопрос 4 | 0 - 2 |

---

## Критерии оценивания

Система учитывает следующие критерии при оценке:

1. **Выполнение коммуникативной задачи** — Кандидат должен ответить на вопрос или задать уточняющий вопрос
2. **Грамматическая корректность** — Единичные ошибки не влияют на оценку; предложения должны быть преимущественно полными
3. **Адекватность описания** — Для заданий с картинкой: схожесть описания с фактическим содержимым (анализируется через RuBERT)
4. **Связность речи** — Логическое построение высказывания

---

## Поток выполнения

```
1. Загрузка входного CSV файла
   ↓
2. Определение типов тестов (с картинкой или без)
   ↓
3. Загрузка и обработка изображений
   ├─ Генерация описаний для каждого изображения
   ├─ Переобработка ответов кандидатов (для заданий с картинками)
   └─ Вычисление метрики схожести
   ↓
4. Построение подсказок для оценивающей модели
   ↓
5. Загрузка fine-tuned модели с LoRA адаптером
   ↓
6. Инференс и предсказание оценок
   ↓
7. Сохранение результатов в CSV файл
```

---

## Оптимизация памяти

Скрипт использует несколько техник для работы даже на GPU с ограниченной памятью:

- **4-bit квантизация** — Уменьшает размер модели в 4 раза
- **Double quantization** — Дополнительная оптимизация параметров квантизации
- **Flash Attention** — Более эффективная реализация attention механизма
- **LoRA адаптер** — Обучаемые параметры занимают <5% от исходной модели
- **Периодическая очистка памяти** — `torch.cuda.empty_cache()` и `gc.collect()`
- **Батчинг** — Обработка примеров порциями

### Требования к GPU

- **Минимум**: 4 GB (VRAM) — при BATCH_SIZE=1
- **Рекомендуется**: 8+ GB — для лучшей производительности

---

## Возможные ошибки и решения

### Ошибка: "Не удается загрузить изображение с URL"
```
[Ошибка загрузки: ...]
```
**Решение**: Проверьте доступность URL, наличие интернета и истечение таймаута REQUEST_TIMEOUT.

### Ошибка: "Out of memory"
```
RuntimeError: CUDA out of memory
```
**Решение**: 
- Уменьшите BATCH_SIZE до 1
- Используйте MAX_SEQ_LENGTH = 512
- Закройте другие приложения, использующие GPU

### Ошибка: "LoRA адаптер не найден"
```
FileNotFoundError: [Errno 2] No such file or directory: 'qwen_sft_exam'
```
**Решение**: Проверьте, что ADAPTER_PATH указывает на существующую директорию с файлами адаптера (adapter_model.safetensors, adapter_config.json).

---

## Архитектура моделей

### Qwen2.5-VL-3B-Instruct
- **Тип**: Vision-Language модель
- **Параметры**: 4 миллиарда
- **Квантизация**: 4-bit (NF4)
- **Назначение**: Анализ изображений и описание картинок

### RuBERT-tiny2
- **Тип**: BERT модель для русского языка
- **Параметры**: ~66 миллионов
- **Размерность эмбеддинга**: 312
- **Назначение**: Вычисление семантической близости описаний

### Fine-tuned Qwen2.5-VL с LoRA адаптером
- **База**: Qwen2.5-VL-3B-Instruct
- **Адаптер**: Low-Rank Adaptation (LoRA)
- **Назначение**: Оценивание устных ответов согласно критериям экзамена

---

## Лицензии

- **Qwen2.5-VL**: Alibaba Cloud (Apache 2.0)
- **RuBERT**: Conversational AI Lab, DeepPavlov (Apache 2.0)
- **Transformers, PyTorch**: Meta AI, Hugging Face (Open Source)
---
